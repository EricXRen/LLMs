{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13ec5863",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# An Introduction to Large Language Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818a351c",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "To convert this notebook to slides and show:\n",
    "\n",
    "`jupyter nbconvert LLMs.ipynb --to slides --TemplateExporter.exclude_input=True --post serve`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4045b5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Language modelling\n",
    "* The training and using of of ChatGPT on paper\n",
    "* Using LLMs\n",
    "* Prompt engineering and fine-tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4910b866",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "## Language Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98df1241",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "<img src=\"img/whatislm.jpg\" alt=\"What is Language Model\" width=\"700\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4ed3b6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Language modelling\n",
    "\n",
    "Language modelling is the task of assigning a probability to sentences in a language. \n",
    "    \n",
    "* Given a sequence of words $(w_1, w_2, w_3, \\ldots ,w_{T})$ of length $T$, a language model assigns a probability \n",
    "    $P(w_{1}, w_{2}, \\ldots ,w_{T})$ to the whole sequence. \n",
    "$\n",
    "\\ \\ \\ \\ \\ \\ \\ \\ \\ P(w_{1}, w_{2}, \\ldots ,w_{T}) = ?\n",
    "$\n",
    "    \n",
    "* This is equivalent to assign a probability for a word following a sequence of words:\n",
    "\n",
    "$\n",
    "\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \n",
    "P(w_1,w_2,\\ldots,w_{T}) = P(w_1,w_2,\\ldots,w_{T-1}) \\times P(w_T|w_1,w_2,\\ldots,w_{T-1})\n",
    "$\n",
    "\n",
    "$\n",
    "\\ \\ \\ \\ \\ \\ \\ \n",
    "\\Rightarrow P(w_T|w_1,w_2,\\ldots,w_{T-1}) = \\dfrac{P(w_1,w_2,\\ldots,w_{T-1})}{P(w_1,w_2,\\ldots,w_{T})}  \n",
    "$\n",
    "\n",
    "\n",
    "**Language model is a probability distribution over sequences of words.**   \n",
    "\n",
    "**Language modelling is essentially a classification problem**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6e60c3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**The Generative part: Decoding**\n",
    "\n",
    "The output of the cat sentence as example:\n",
    "\n",
    "* Input: The cat sat on the ...\n",
    "* Output: [mat(0.21), rug(0.17), chair(0.08), stairs(0.02), ... floor(0.005)]\n",
    "\n",
    "Which word should the model return?\n",
    "\n",
    "* the most likely one: *mat* has the hightest probability\n",
    "* top K or Top P: *[mat(0.21), rug(0.17), chair(0.08)]*\n",
    "* randomly sample over distribution: *[rug(0.17), floor(0.005)]*\n",
    "\n",
    "**temperature** is used to control the randomness of output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7622ecb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Examples of using language models\n",
    "\n",
    "**word suggestions** when typing on your phone or Google search\n",
    "\n",
    "**speech recognition** Given $A$ is a sequence of acoustic symbols and $W$ a string of words\n",
    "\n",
    "$\\ \\ \\ \\ \\hat{W} = \\underset{W}{argmax}\\ P(W|A)$ \n",
    "\n",
    "Apply Bayes' rule $P(W|A) = \\dfrac{P(W) \\times P(A|W)}{P(A)}$:\n",
    "\n",
    "$\n",
    "\\ \\ \\ \\ \\hat{W} = \\underset{W}{argmax}\\ P(W) \\times P(A|W)\n",
    "$\n",
    "\n",
    "**Translations**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d0ad5a",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The speech to text recogniser should decide in favor of a word string $W$ satisfying\n",
    "\n",
    "where $P(W|A)$ is the probability that the words $W$ were spoken, given the evidence $A$ was observed.\n",
    "\n",
    "$\\ \\ \\ \\ A=a_1, a_2, \\ldots, a_m \\ \\ \\ \\ \\ \\ a_i\\in{\\mathcal{A}}$\n",
    "denote a sequence of acoustic symbols from audio signals\n",
    "\n",
    "$\\ \\ \\ \\ W = w_1,w2,\\ldots, w_{n} \\ \\ \\ \\ \\ \\ w_i \\in{\\mathcal{W}}$\n",
    "denote a string of n words, each belonging to a fixed vocabulary $\\mathcal{W}$\n",
    "\n",
    "Same for the machine translation problem: \n",
    "The output is a probability across the target vocabulary and   \n",
    "it has computational access to the history.\n",
    "\n",
    "The same language model part is also called **decoder**, which we will touch later.\n",
    ": ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410e4315",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Traditional approach to language modelling\n",
    "\n",
    "<img src=\"img/prehistory_dinosaur_02.png\" alt=\"history\" width=100>\n",
    "\n",
    "* Counting in large corpus of text ~ Law of large numbers!\n",
    "\n",
    "* A n-gram is a chunk of n consecutive words.\n",
    "* 3-gram example:  \n",
    "\n",
    "$\n",
    "\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ P(w_T=m|w_1,w_2,\\ldots,w_{T-3}, w_{T-2},w_{T-1}) \\\\ \n",
    "\\ \\ \\ \\ \\ \\ \\ \\ \\ \\approx P(w_T=m|w_{T-3},w_{T-2},w_{T-1})\n",
    "$\n",
    "* Collect statistics on different n-grams' frequency to estimate: \n",
    "\n",
    "$\n",
    "\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\hat{p}(w_T=m|w_{T-3}, w_{T-2},w_{T-1}) =\\dfrac{\\#(w_{T-3},w_{T-2},w_{T-1}, w_{T})}{\\#(w_{T-3},w_{T-2},w_{T-1})} \n",
    "$\n",
    "\n",
    "* Smoothing techniques and other tricks to deal with sparsity problems\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c004c2a1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Neural Networks for language modelling\n",
    "\n",
    "**MLP**: n-gram of words as input (fixed window) and the probability distribution over the next word as output\n",
    "\n",
    "<img src=\"img/multiclass_softmax.webp\" alt=\"Last layer of classification with softmax\" width=700>\n",
    "\n",
    "[Ref: A Neural Probabilistic Language Model](https://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a862d07a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**RNNs, LSTM, GRU**\n",
    "<img src=\"img/rnn_01.png\" alt=\"RNN\" width=600>\n",
    "\n",
    "---\n",
    "**Sequence to sequence model**\n",
    "|seq2seq model  | seq2seq unrolled over time|\n",
    "|:---:|:---:|\n",
    "|<img src=\"img/seq2seq_simple.webp\" alt=\"seq2seq model\" width=\"300\"/>|<img src=\"img/seq2seq.webp\" alt=\"seq2seq model\" width=\"450\"/>|\n",
    "\n",
    "[Ref: Sequence to Sequence Learning with Neural Networks](https://arxiv.org/abs/1409.3215)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb53c54d",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "**RNN Advantages**:\n",
    "* Can process any length input\n",
    "* Computation for step t can (in theory) use information from any steps back\n",
    "* Model size doesn’t increase for longer input context\n",
    "* Same weights applied on every timestep, so there is symmetry in how inputs are processed.\n",
    "\n",
    "**RNN Disadvantages**:\n",
    "* Recurrent computation is slow\n",
    "* In practice, difficult to access information from many steps back"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260ed3da",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Transformer Architecture\n",
    "\n",
    "\n",
    "<img src=\"img/transformer.png\" alt=\"Simplified Transformer\" width=\"400\"/>\n",
    "\n",
    "[Ref: Attention Is All You Need](https://arxiv.org/abs/1706.03762)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06cd338",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Transformer overview\n",
    "\n",
    "|  |  |\n",
    "|:---:|:---:|\n",
    "|<img src=\"img/tf1.png\" alt=\"Transformer step by step\" width=\"400\"/>|<img src=\"img/tf2.png\" alt=\"Transformer step by step\" width=\"400\"/>|\n",
    "|<img src=\"img/tf4.png\" alt=\"Transformer step by step\" width=\"400\"/>|<img src=\"img/tf3.png\" alt=\"Transformer step by step\" width=\"400\"/>|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd7f33c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**The Transformer Architecture**\n",
    "\n",
    "* Removes the RNN completely\n",
    "* Keeps the encoder-decoder architecture, and use attentions on both parts and between\n",
    "* Uses the ResNet's structure: the skip connections to train deeper networks\n",
    "* Uses the position encoding to encode the token's position information\n",
    "* Use the input enbedding layer to learned vector representation of each word  \n",
    "\n",
    "---\n",
    "\n",
    "* More details on training of the RNN and Transformer models will be covered in the future\n",
    "* Previous talks on these topics from [**Deep learning Guild**](https://www.google.com) and [**NLP Guild**](https://www.google.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c53fb89",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Large Language Models (LLMs)\n",
    "\n",
    "* Take advantages of parallel computing based on the transformer architecture\n",
    "* Trained on massive datasets of text (**trillions of tokens**, Internet scale)\n",
    "* Transformers with **billions parameters**\n",
    "* Thousand of latest GPUs, months of training, and cost millions\n",
    "\n",
    "___\n",
    "* Implicitly learned syntax and semantics of human language, the general knowledge and \"understanding\" about the world\n",
    "* Become general purpose models that excel at a wide range of tasks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f129870",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Types of LLMs\n",
    "\n",
    "<img src=\"img/TypeOfLLMs.png\" alt=\"Type of LLMs\" width=800>\n",
    "\n",
    "* Discriminative LM: predict next word in a sequence of words based on previous words\n",
    "* Generative LM: Generate text by sampling from the probability distribution over sequence of words \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845e3037",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Training of ChatGPT on paper\n",
    "\n",
    "* Pre-training\n",
    "* Supervised Fine Tuning\n",
    "* Reinforcement Learning from Human Feedback (RLHF)\n",
    "\n",
    "<img src=\"img/chatgpt-training_1.png\" alt=\"Training of chatGPT\" width=700>\n",
    "\n",
    "[Ref: Chip Huyen's Blog](https://huyenchip.com/2023/05/02/rlhf.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d040105b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Pre-training\n",
    "\n",
    "![Alt_text](img/chatGPT_training04.png \"Generative Pretraining\")\n",
    "\n",
    "* Supervised learning on unlabled data\n",
    "* Trained on vast amont of data (1 trillion tokens are equivalent to 15 million books)\n",
    "* Will run out of Internet data in the next few years with this trend of data consumption\n",
    "* Many companies have changed their data terms to prevent others from scraping their data for LLMs\n",
    "* 99% of the computing time and flops are used on this pre-trainig step\n",
    "  \n",
    "\n",
    "[Ref: LLaMA: Open and Efficient Foundation Language Models](https://arxiv.org/pdf/2302.13971.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb55a28",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Shoggoth with a smiley face analogy**\n",
    "* The pretrained model is an untamed monster\n",
    "* This monster was then finetuned on higher quality data\n",
    "* Then the finetuned model was further polished using RLHF to make it customer-appropriate\n",
    "\n",
    "<img src=\"img/shoggoth.jpg\" alt=\"Shoggoth with smiley face\" width=400>\n",
    "\n",
    "\n",
    "**Alignment** - Steering LLMs to intended goals and interests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25460d8d",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "* The pretrained model is an untamed monster because \n",
    "  * it learned the powerful general representations\n",
    "  * it's not trained on specific useful tasks\n",
    "  * it was trained on indiscriminate data scraped from the Internet: misinformation, propaganda, conspiracy theories, or attacks against certain demographics.\n",
    "* This monster needs to be finetuned on higher quality data – \n",
    "StackOverflow, Quora and human annotations – which makes it somewhat socially acceptable.\n",
    "* Then the finetuned model was further polished using RLHF to make it customer-appropriate, finally we get a smiley face."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a18293",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Supervised Fine Tuning\n",
    "\n",
    "* To optimize the pretrained model to generate useful responses\n",
    "* To show the language model examples of how to appropriately respond\n",
    "* To relieve the user burden of design their own prompts ([GPT3 is a few-shot learner](https://arxiv.org/abs/2005.14165))\n",
    "* OpenAI hire 40+ high quality labelers to create around 13,000 **(prompt, response) pairs** for InstructGPT.\n",
    "* Prompts are designed for different use cases (e.g. question answering, summarization, translation)\n",
    "\n",
    "Example training dataset: [Training language models to follow instructions with human feedback, page 26~33](https://arxiv.org/pdf/2203.02155.pdf)\n",
    "\n",
    "\n",
    "<img src=\"img/ChatGPT_training01.png\" alt=\"SFV\" width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3dbdad1",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "First part of the alignment is the Supervised Fine Tuning:\n",
    "* High quality labelers provide demonstrations of the desired  \n",
    "behaviour on the input prompt distribution\n",
    "\n",
    "* Fine-tune a pretrained GPT-3 model on this data using supervised learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda0013a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"img/ChatGPT_SFT.png\" alt=\"Supervised Fine Tunning and RLHF\" width=700>\n",
    "\n",
    "[Ref: Training language models to follow instructions with human feedback](https://arxiv.org/abs/2203.02155)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bab27ef",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Reinforcement Learning from Human Feedback (RLHF)\n",
    "\n",
    "**The goal of Alignment**\n",
    "\n",
    "Given a particular history, the objective is to maximise the probability \n",
    "the model assigns to the sequence of tokens in the corresponding response.\n",
    "\n",
    "<img src=\"img/imitation_game.jpeg\" alt=\"The goal of Alignment\" width=\"700\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e2a3a7",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "**The goal of Alignment** is kind of **Brainwashing**.\n",
    "\n",
    "**RLFH** Originally developed for training simple robots in simulated environments and Atari\n",
    "games  it has recently been applied to fine-tuning language models \n",
    "\n",
    "Teach the model by having it mimic how humans respond in conversations.  \n",
    "The model then creates an **expert policy**, which acts like a rule book for how the model should respond to requests. \n",
    "\n",
    "* Step 1: Collect comparison data, and train a reward model. \n",
    "  * For a given input, use the existing model to generate several outputs \n",
    "  * Labelers then indicate which output they prefer by ranking the outputs\n",
    "* Train a reward model to predict the human-preferred output.\n",
    "* Optimize a policy against the reward model using PPO. \n",
    "\n",
    "The output of the Reward Model is a scalar as reward. The supervised policy is fine-tuned to  optimize this reward using the PPO algorithm.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e423f28",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Reward model\n",
    "\n",
    "<img src=\"img/reward_model.jpeg\" alt=\"Reward model\" width=\"500\"/>\n",
    "\n",
    "**Logistic Regression for Scorecard**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603a8cca",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Proximal Policy Optimization\n",
    "* Policy is the mapping from action space to state space\n",
    "* Policy gradient optimization algorithm for updating an existing policy to gain reward\n",
    "\n",
    "<img src=\"img/policy_model.png\" alt=\"Policy model\" width=\"600\"/>\n",
    "\n",
    "[ref: How ChatGPT is Trained](https://www.youtube.com/watch?v=VPRSBzXzavo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38841504",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "**PPO**\n",
    "\n",
    "* Policy: A policy, in Reinforcement Learning terminology, is a mapping from action space to state space. It can be imagined to be instructions for the RL agent, in terms of what actions it should take based upon which state of the environment it is currently in.\n",
    "\n",
    "* PPO is a policy gradient optimization algorithm, that is, in each step there is an update to an existing policy to seek improvement on certain parameters It ensures that the update is not too large, that is the old policy is not too different from the new policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fce37d8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Performance\n",
    "\n",
    "<img src=\"img/PPO_performance_02.png\" alt=\"Human evaluations of various models' performance\" width=700>\n",
    "\n",
    "[Ref: Training language models to follow instructions with human feedback](https://arxiv.org/abs/2203.02155)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c38836",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Recap\n",
    "\n",
    "<img src=\"img/chat_GPT_training_pipeline.png\" alt=\"Training of chatGPT\" width=700>\n",
    "\n",
    "[Ref: Andrew Karpathy's Microsoft BUILD Talk: State of GPT](https://www.youtube.com/watch?v=bZQun8Y4L2A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5a59fe",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Process of using ChatGPT\n",
    "\n",
    "<img src=\"img/usingChatGPT.png\" alt=\"Using ChatGPT\" width=\"500\"/>\n",
    "\n",
    "**Content Moderation!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd627fd",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "OpenAI's **Moderation** API\n",
    "\n",
    "The moderations endpoint can check whether content complies with OpenAI's usage policies. \n",
    "\n",
    "The models classifies the following categories:\n",
    "* hate\n",
    "* hate/threatening\n",
    "* harassment\n",
    "* self-harm, self-harm/intent, self-harm/instructions\n",
    "* sexual sexual services sexual/minors\n",
    "* violence violence/graphic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d20434",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## Using LLMs \n",
    "\n",
    "### Tasks\n",
    "* Prompting: Generate text or even image directly\n",
    "* Embedding: Extract semantic information from unstructured data for building applicaitons\n",
    "\n",
    "### Applications\n",
    "* Search\n",
    "* Generative\n",
    "* Summarise, Rewrite, Extract\n",
    "* Classify, Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b22a2c4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Way of using LLMs\n",
    "\n",
    "#### Model-as-a-Service via API\n",
    "\n",
    "* OpenAI API examples:\n",
    "  * Chat: given a conversation, return a response\n",
    "  * Completions: Given a prompt, return multiple predicted completions, with probabilities of alternative tokens at each position\n",
    "  * Edits: given a prompt and an instruction, the model will return an edited version of the prompt\n",
    "  * Image: create, edit, modify images\n",
    "  * Embeddings: get a vector representation of a given input that can be easily consumed by machine learning models and algorithms\n",
    "* Google has similar APIs: PaLM, Imagen, Codey, Chirp, and Embeddings\n",
    "\n",
    "#### Fine-tune an existing third-party Model in a managed environment via API\n",
    "\n",
    "#### Open-source model in a managed environment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4f6e0b",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "**Model-as-a-Service via API** \n",
    "\n",
    "The Embeddings API is a powerful tool that can be used to improve the performance of a variety of applications.\n",
    "It can be used for a variety of tasks, such as search, clustering, recommendations, and anomaly detection.\n",
    "\n",
    "\n",
    "**Fine-tune an existing third-party Model in a managed environment via API**\n",
    "\n",
    "**Advantages for both above approaches**\n",
    "* Low barrier to entry and convenient to implement \n",
    "* Access to the latest, the largest and most sophisticated LLMs\n",
    "\n",
    "**Limitations**\n",
    "* Data residency and privacy\n",
    "* Potentially higher cost\n",
    "* Dependency on third party\n",
    "\n",
    "\n",
    "**Open-source model in a managed environment**\n",
    "\n",
    "**Advantages**\n",
    "* Wide range of choice\n",
    "* Potentially lower cost\n",
    "* Independence\n",
    "\n",
    "**Tradeoffs**\n",
    "* Complexity: Setting up and maintaining a LLM requires data science and engineering expertise. \n",
    "* Smaller scale, and narrower performance \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424a601d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Prompt Engineering\n",
    "\n",
    "Steering an LLM’s behavior towards a particular outcome without updating the model’s weights/parameters.\n",
    "\n",
    "\n",
    "### Prompting Design\n",
    "Effectively communicating with LLMs to get desired results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdc91e1",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "**Prompts**: The text feed to the model\n",
    "\n",
    "**Prompt engineering**, also known as in-context prompting, is a method for steering an LLM’s behavior towards a particular outcome without updating the model’s weights/parameters. It’s the process of effectively communicating with LLMs to get desired results. Prompt engineering is used on a variety of tasks from question answering to arithmetic reasoning.\n",
    "\n",
    "Prompts are a set of text instructions that LLMs receive to generate a response or complete a task. There are several types of prompts like summarization, inferring or transforming. Thus, Prompt engineering aims to take these prompts and help the model to achieve high accuracy and relevance in its outputs.\n",
    "\n",
    "The two most common types of prompting are zero-shot and few-shot prompting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4faf45d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Zero-shot Prompting\n",
    "\n",
    "### Few-shot Prompting (In-context Learning)\n",
    "\n",
    "### Chain-of-Thought Prompting "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f48581",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "**Zero-shot Prompting**\n",
    "\n",
    "Zero-shot learning involves feeding the task to LLMs without any examples that indicate the desired output,   \n",
    "hence the name zero-shot. \n",
    "\n",
    "For example, one could just feed a model a sentence and expect it to output the sentiment of that sentence.\n",
    "\n",
    "\n",
    "**Few-shot Prompting**\n",
    "\n",
    "Few-shot learning, on the other hand, involves providing the model with a small  \n",
    "number of high-quality examples that include both input and desired output for  \n",
    "the target task.  \n",
    "By seeing these good examples, the model can better understand the user's intention  \n",
    "and criteria for generating accurate outputs.  \n",
    "\n",
    "As a result, few-shot learning often leads to better performance compared to  \n",
    "zero-shot learning.  \n",
    "However, this approach can consume more tokens and may encounter context length  \n",
    "limitations when dealing with long input and output text.\n",
    "\n",
    "This kind of *in-context learning* using few-shot prompting by offering  \n",
    "demonstrations in the prompt can guide the LLM to carry out the task. In other words,  \n",
    "conditioning the model on a selection of task-specific examples helps   \n",
    "improve the model’s performance.\n",
    "\n",
    "\n",
    "**Chain-of-Thought (CoT) prompting**\n",
    "\n",
    "Chain-of-Thought prompting generates a sequence of short sentences known as  \n",
    "**reasoning chains**. These describe step-by-step reasoning logic leading to   \n",
    "the final answer with more benefits seen for complex reasoning tasks. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6359d73e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In summary:\n",
    "\n",
    "![prompt summary](img/zero-cot.webp)\n",
    "\n",
    "Ref and image soure: [Kojima et al. (2022)](https://arxiv.org/abs/2205.11916)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccbb626",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### A variety of fancy prompting ideas\n",
    "\n",
    "* ReAct: Combines **Re**asoning and **Act**ing with LLMs.  \n",
    "    *\"What's the age of the universe?\" -> \"I need to find more information on the universe\" -> \"[search on Wikipedia]\"*\n",
    "* Code as Reasoning: When given a question, try to write code that solves this question. Then send the code to a programmatic runtime to get the result. \n",
    "* Automatic Prompt Design: Automating the generation and selection of prompts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760d1a6c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Formalising Prompts\n",
    "\n",
    "There are a few parts of a prompt that are quite common:\n",
    "\n",
    "<img src=\"img/PromptParts.png\" alt=\"Formal prompt\" width=150>\n",
    "\n",
    "[Ref and image source: Learning Prompting](https://learnprompting.org/docs/basics/formalizing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d478fd41",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "* A role\n",
    "* An instruction / task\n",
    "* A question\n",
    "* Context\n",
    "* Examples (few shot)\n",
    "\n",
    "Not all of these occur in every prompt, and there is no standard order for them. The following is another example: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265ffae1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Fine-Tuning\n",
    "\n",
    "* Task specific tuning can make LLMs more suitable for domain problems and more reliable\n",
    "* Further train the model on new data\n",
    "\n",
    "### Parameter-Efficient Fine-tuning (PEFT)\n",
    "\n",
    "<img src=\"img/model_tuning.jpg\" alt=\"Model tuning\" width=\"400\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ce75c0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Prompt Tuning\n",
    "\n",
    "Tune a vector that get sent prepended to the input text\n",
    "\n",
    "<img src=\"img/prompt_tuning.jpg\" alt=\"Prompt tuning\" width=\"400\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eef7c67",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "**Parameter-efficient fine-tuning** is a method of fine-tuning that  \n",
    "focuses on training only a subset of the pre-trained model’s parameters.  \n",
    "This approach involves identifying the most important parameters for the  \n",
    "new task and only updating those parameters during training. Doing so,  \n",
    "PEFT can significantly reduce the computation required for fine-tuning.\n",
    "\n",
    "**Prompt-tuning** is an efficient, low-cost way of adapting a LLM to new   \n",
    "downstream tasks without retraining the model and updating its weights.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ce8361",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Debatable Topics and Pitfalls of LLMs\n",
    "\n",
    "LLMs are extremely powerful, but it is debatable on what they are actually doing.\n",
    "\n",
    "* Stochastic parrot\n",
    "* Emergent abilities\n",
    "* Citing sources on generations\n",
    "* Hallucinations\n",
    "* Bias\n",
    "* Prompt Hacking\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c98c18",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "* **Stochastic parrot or not?**: Although large language models are good at generating convincing language, many people believe LLMa do not actually understand the meaning of the language it is processing\n",
    "\n",
    "* **Emergent abilities**: Emergent abilities are skills that suddenly and unpredictably show up (emerge) in AI systems. Theese abilities are not present in smaller models but it seems that there are qualitative changes that come from scaling the AI language models. There are greate debate on how to define and how to measure them.\n",
    "\n",
    "* **Hallucinations**: LLMs will frequently generate falsehoods when asked a question that they do not know the answer to. Sometimes they will state that they do not know the answer, but much of the time they will confidently give a wrong answer.\n",
    "\n",
    "* **Bias**: LLMs are often biased towards generating stereotypical responses. Even with safe guards in place, they will sometimes say sexist/racist/homophobic things. Be careful when using LLMs in consumer-facing applications, and also be careful when using them in research (they can generate biased results).\n",
    "\n",
    "* **Citing Sources**: LLMs for the most part cannot accurately cite sources. This is because they do not have access to the Internet, and do not exactly remember where their information came from. They will frequently generate sources that look good, but are entirely inaccurate.  \n",
    "(Strategies like search augmented LLMs can often fix this problem)\n",
    "\n",
    "* **Prompt Hacking**:  Users can often trick LLMs into generating any content they want.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ac961d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Recap**\n",
    "\n",
    "* Language modelling is to learn the probability distribution of word sequences\n",
    "* Transformers are by far the latest and best way to learn this distribution\n",
    "* LLMs become general purpose models that excel at a wide range of tasks\n",
    "* Proper prompts / tuning can condition the generative model before query to extract uesful information\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a213dc87",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![alt text](img/message_from_Bard.png \"message from Bard\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aaef14a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Questions and Discussion\n",
    "\n",
    "<img src=\"img/questions_discussion.png\" alt=\"Questions and Discussions\" width=300>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c150ed2",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "torch-env",
   "language": "python",
   "name": "torch-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "317.8px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
