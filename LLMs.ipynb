{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13ec5863",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# An Introduction to Large Language Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818a351c",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "To convert this notebook to slides and show:\n",
    "\n",
    "`jupyter nbconvert LLMs.ipynb --to slides --TemplateExporter.exclude_input=True --post serve`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4910b866",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "## Language Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4ed3b6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Language modelling\n",
    "\n",
    "Language modelling is the task of assigning a probability to sentences in a language. \n",
    "    \n",
    "* Given a sequence of words $(w_1, w_2, w_3, \\ldots ,w_{T})$ of length $T$, a language model assigns a probability \n",
    "    $P(w_{1}, w_{2}, \\ldots ,w_{T})$ to the whole sequence. \n",
    "$\n",
    "\\ \\ \\ \\ \\ \\ \\ \\ \\ P(w_{1}, w_{2}, \\ldots ,w_{T}) = ?\n",
    "$\n",
    "    \n",
    "* This is equivalent to assign a probability for a word following a sequence of words:\n",
    "\n",
    "$\n",
    "\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \n",
    "P(w_1,w_2,\\ldots,w_{T}) = P(w_1,w_2,\\ldots,w_{T-1}) \\times P(w_T|w_1,w_2,\\ldots,w_{T-1})\n",
    "$\n",
    "\n",
    "$\n",
    "\\ \\ \\ \\ \\ \\ \\ \n",
    "\\Rightarrow P(w_T|w_1,w_2,\\ldots,w_{T-1}) = \\dfrac{P(w_1,w_2,\\ldots,w_{T-1})}{P(w_1,w_2,\\ldots,w_{T})}  \n",
    "$\n",
    "\n",
    "* Language model is a probability distribution over sequences of words. \n",
    "* Language modelling is essentially a classification problem\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7622ecb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Examples of using language models\n",
    "#### speech recognition\n",
    "\n",
    "$\\ \\ \\ \\ A=a_1, a_2, \\ldots, a_m \\ \\ \\ \\ \\ \\ a_i\\in{\\mathcal{A}}$\n",
    "denote a sequence of acoustic symbols from audio signals\n",
    "\n",
    "$\\ \\ \\ \\ W = w_1,w2,\\ldots, w_{n} \\ \\ \\ \\ \\ \\ w_i \\in{\\mathcal{W}}$\n",
    "denote a string of n words, each belonging to a fixed vocabulary $\\mathcal{W}$\n",
    "\n",
    "The speech to text recogniser should decide in favor of a word string $W$ satisfying\n",
    "\n",
    "$\\ \\ \\ \\ \\hat{W} = \\underset{W}{argmax}\\ P(W|A)$\n",
    "\n",
    "where $P(W|A)$ is the probability that the words $W$ were spoken, given the evidence $A$ was observed.\n",
    "\n",
    "Apply Bayes' rule $P(W|A) = \\dfrac{P(W) \\times P(A|W)}{P(A)}$:\n",
    "\n",
    "$\n",
    "\\ \\ \\ \\ \\hat{W} = \\underset{W}{argmax}\\ P(W) \\times P(A|W)\n",
    "$\n",
    "\n",
    "#### Translations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410e4315",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Traditional approach to language modelling\n",
    "\n",
    "* Law of large numbers: counting in large corpus of text\n",
    "\n",
    "* A n-gram is a chunk of n consecutive words.\n",
    "* n-order Markov prpoerty assumption\n",
    "$\n",
    "\\ \\ \\ \\ \\ \\ \\ \n",
    "P(w_T=m|w_1,w_2,\\ldots,w_{T-3}, w_{T-2},w_{T-1}) \\approx P(w_T=m|w_{T-3},w_{T-2},w_{T-1}), 3rd\\ order\\ estimation\\ example\n",
    "$\n",
    "* Collect statistics about how frequent different n-grams are and use these to\n",
    "predict next word.\n",
    "$\n",
    "\\ \\ \\ \\ \\ \\ \\ \n",
    "\\hat{p}(w_T=m|w_{T-3}, w_{T-2},w_{T-1}) =\\dfrac{\\#(w_{T-3},w_{T-2},w_{T-1}, w_{T})}{\\#(w_{T-3},w_{T-2},w_{T-1})}\n",
    "$\n",
    "\n",
    "* Smoothing techniques and other tricks to deal with sparsity problems\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c004c2a1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Neural Networks for language modelling\n",
    "\n",
    "#### MLP: n-gram of words as input (fixed window) and the probability distribution over the next word as output\n",
    "#### RNNs, LSTM, GRU\n",
    "![Alt text](img/rnn_01.png \"RNN\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb53c54d",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "**RNN Advantages**:\n",
    "* Can process any length input\n",
    "* Computation for step t can (in theory) use information from any steps back\n",
    "* Model size doesn’t increase for longer input context\n",
    "* Same weights applied on every timestep, so there is symmetry in how inputs are processed.\n",
    "\n",
    "**RNN Disadvantages**:\n",
    "* Recurrent computation is slow\n",
    "* In practice, difficult to access information from many steps back"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d795a1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Seq2seq\n",
    "![Alt text](img/seq_to_seq.png \"Sequence to Sequence architecture\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260ed3da",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Transformer\n",
    "![Alt text](img/transformer.png \"Simplified Transformer\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3841b8ae",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![Alt text](img/transformer_simple.png \"Transformer\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c53fb89",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Large Language Models (LLMs)\n",
    "\n",
    "* LLMs are language model consisting of billions parameters\n",
    "* Trained on trillions of tokens\n",
    "* Take advantages of parallel computing based on the transformer architectures\n",
    "* Become general purpose models that excel at a wide range of tasks\n",
    "* Implicitly learned syntax and semantics of human language, the general \"knowledge\" about the world\n",
    "\n",
    "\n",
    "![Alt text](img/TypeOfLLMs.png \"Type of LLMs\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845e3037",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Training of ChatGPT on paper\n",
    "\n",
    "* Pre-training\n",
    "* Supervised Fine Tuning\n",
    "* Reinforcement Learning from Human Feedback (RLHF)\n",
    "\n",
    "\n",
    "![Alt text](img/chatgpt-training_1.png \"Training of chatGPT\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d040105b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Pre-training\n",
    "\n",
    "![Alt_text](img/chatGPT_training04.png \"Generative Pretraining\")\n",
    "\n",
    "* Supervised learning on unlabled data\n",
    "* Trained on vast amont of data (1 trillion tokens are equivalent to 15 million books)\n",
    "* We’ll run out of Internet data in the next few years with this this trend of data consuming\n",
    "* Many companies have changed their data terms to prevent others from scraping their data for LLMs\n",
    "* The Internet is being rapidly populated with LLM generated data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9c1e2a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Shoggoth with a smiley face analogy**\n",
    "\n",
    "![Alt text](img/shoggoth.jpg \"Type of LLMs\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb55a28",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "**Shoggoth with a smiley face analogy**\n",
    "\n",
    "* The pretrained model is an untamed monster because it was trained on indiscriminate data scraped from the Internet: misinformation, propaganda, conspiracy theories, or attacks against certain demographics.\n",
    "* This monster was then finetuned on higher quality data – StackOverflow, Quora and human annotations – which makes it somewhat socially acceptable.\n",
    "* Then the finetuned model was further polished using RLHF to make it customer-appropriate, e.g. giving it a smiley face."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a18293",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Supervised Fine Tuning\n",
    "\n",
    "* To optimize the pretrained model to generate useful responses\n",
    "* To show the language model examples of how to appropriately respond\n",
    "* To relieve the user burden of design their own prompts ([GPT3 is a few-shot learner](https://arxiv.org/abs/2005.14165))\n",
    "* OpenAI hire 40 high quality labelers to create around 13,000 (prompt, response) pairs for InstructGPT.\n",
    "* Prompts are designed for different use cases (e.g. question answering, summarization, translation)\n",
    "\n",
    "Example training dataset: [Training language models to follow instructions with human feedback, page 26~33](https://arxiv.org/pdf/2203.02155.pdf)\n",
    "\n",
    "\n",
    "![Alt_text](img/ChatGPT_training01.png \"Generative Pretraining\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda0013a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![Alt_text](img/ChatGPT_SFT.png \"Supervised Fine Tunning and RLHF\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c041b28a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Reinforcement Learning from Human Feedback (RLHF)\n",
    "\n",
    "#### Reward model\n",
    "\n",
    "#### Proximal Policy Optimization\n",
    "* Policy\n",
    "* Policy gradient optimization algorithm for updating an existing policy to gain reward\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38841504",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "**PPO**\n",
    "\n",
    "* Policy: A policy, in Reinforcement Learning terminology, is a mapping from action space to state space. It can be imagined to be instructions for the RL agent, in terms of what actions it should take based upon which state of the environment it is currently in.\n",
    "\n",
    "* PPO is a policy gradient optimization algorithm, that is, in each step there is an update to an existing policy to seek improvement on certain parameters It ensures that the update is not too large, that is the old policy is not too different from the new policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fce37d8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Performance\n",
    "\n",
    "![Alt_text](img/PPO_performance.png \"Human evaluations of various models' performance\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5a59fe",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Process of using ChatGPT\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d20434",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "\n",
    "## How to Use LLMs in the Enterprise\n",
    "\n",
    "### Model-as-a-Service via API\n",
    "**Advantages**\n",
    "* Low barrier to entry and convenient to implement \n",
    "* Access to the latest, the largest and most sophisticated LLMs\n",
    "**Limitations**\n",
    "* Data residency and privacy\n",
    "* Potentially higher cost\n",
    "* Dependency on third party\n",
    "\n",
    "### Open-source model in a managed environment\n",
    "**Advantages**\n",
    "* Wide range of choice\n",
    "* Potentially lower cost\n",
    "* Independence\n",
    "**Tradeoffs**\n",
    "* Complexity: Setting up and maintaining a LLM requires data science and engineering expertise. \n",
    "* Smaller scale, and narrower performance \n",
    "\n",
    "### Fine-tune an existing third-party Model in a managed environment via API\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ce8361",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "## Debatable Topics and Pitfalls of LLMs\n",
    "\n",
    "LLMs are extremely powerful, but there are debatable on what they are actually doing.\n",
    "\n",
    "* **Stochastic parrot or not?**: Although large language models are good at generating convincing language, many people believe LLMa do not actually understand the meaning of the language it is processing\n",
    "\n",
    "* **Emergent abilities**: Emergent abilities are skills that suddenly and unpredictably show up (emerge) in AI systems. Theese abilities are not present in smaller models but it seems that there are qualitative changes that come from scaling the AI language models. There are greate debate on how to define and how to measure them.\n",
    "\n",
    "* **Hallucinations**: LLMs will frequently generate falsehoods when asked a question that they do not know the answer to. Sometimes they will state that they do not know the answer, but much of the time they will confidently give a wrong answer.\n",
    "\n",
    "* **Bias**: LLMs are often biased towards generating stereotypical responses. Even with safe guards in place, they will sometimes say sexist/racist/homophobic things. Be careful when using LLMs in consumer-facing applications, and also be careful when using them in research (they can generate biased results).\n",
    "\n",
    "* **Citing Sources**: LLMs for the most part cannot accurately cite sources. This is because they do not have access to the Internet, and do not exactly remember where their information came from. They will frequently generate sources that look good, but are entirely inaccurate.  \n",
    "(Strategies like search augmented LLMs can often fix this problem)\n",
    "\n",
    "* **Prompt Hacking**:  Users can often trick LLMs into generating any content they want.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c98c18",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424a601d",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b106237",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0265c5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eaa508e8",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "torch-env",
   "language": "python",
   "name": "torch-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "317.8px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
